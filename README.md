# Tree-Based-Methods

# Main Tasks:

- Data Preprocessing- Handling missing data with "mean substitution" strategy
- Select 13 features with highest Coefficient of Variation and plot scatter plots and box plots
- Train a Random Forest to classify the dataset without any compensation for class imbalance
- Evaluate performance using confusion matrix, AUC, ROC and Out of Bag Error
- Use SMOTE technique to handle class imbalance and fit a random forest model 
- Perform classification using Logistic Model Trees (WEKA) without compensation for class imbalance
- Use 5-fold Cross Validation to estimate the error of trained model and compare with test error
- Use SMOTE to pre-process data to compensate for class imbalance and train a Logistic Model Tree 
- Compare the methods adopted above
